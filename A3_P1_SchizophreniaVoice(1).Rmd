---
title: "Assignment2_Part1_VoiceInSchizophrenia"
author: "Pernille Berg Lassen"
date: "July 17, 2016"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 2 - Part 1 - Assessing voice in schizophrenia

Schizophrenia has been associated with "inappropriate" voice, sometimes monotone, sometimes croaky. A few studies indicate that pitch might be an index of schizophrenia. However, an ongoing meta-analysis of the literature (which you will have a go at in the last assignment) indicates that pitch mean and standard deviation are only weak indicators of diagnosis. Can we do better with our new fancy complex skills?

The corpus you are asked to analyse is a set of voice recordings from people with schizophrenia (just after first diagnosis) and 1-1 matched controls (on gender, age, education). Each participant watched 10 videos of triangles moving across the screen and had to describe them (so you have circa 10 recordings per person). I have already extracted the pitch once every 10 milliseconds and you will have to use this data to assess differences in the voice.

N.B. Question to be answered via email to Celine: can you characterize voice in schizophrenia as acoustically different? Report the methods you used to answer this question and the results from the analyses. Add a couple of lines trying to interpret the results (make sense of the difference). E.g. People with schizophrenia tend to have high-pitched voice, and present bigger swings in their prosody than controls. Add a couple of lines describing limitations of the data/analyses if any is relevant.

N.B. There are looots of files to be dealt with. Probably too many for your computer. This is a challenge for you. Some (complementary) possible strategies: You can select a subset of files only (and you have to justify your choice). You can learn how to use the apply() or map() functions. You can coordinate with classmates.

```{r}
setwd("C:/Users/Ejer/Desktop/3. semester/Experimental Methods 3/Assignment2")
library(pacman)
p_load(modelr,lmerTest,ggplot2,dplyr,MuMIn,stringr,tidyverse,plyr,Metrics,groupdata2,pastecs,crqa, data.table,readr,raster)

part1 = read.delim("Pitch/Study1D0S101T1_f0.txt")

```

1. In the course of this assignment you have to first select one datafile and figure out how to:

- Extract "standard" descriptors of pitch: Mean, standard deviation, range
- Extract less "standard" descriptors of pitch you can think of (e.g. median, iqr, mean absoluted deviation, coefficient of variation)
- Extract "complex" descriptors: recurrence quantification analysis

```{r}
#Extracting standard descriptors of pitch
summary(part1)
#Getting mean, sd, range median, min, max, SE etc.
round(stat.desc(part1$f0, norm = T),6)

#Calculating interquatile range (IQR), mean absoluted deviation (mad) and coefficient of variance (cv - also avaliable in stat.desc)
IQR(part1$f0)
mad(part1$f0)
cv(part1$f0)

#Extracting complex descriptors - crqa compares phase spaces in two time series with a specified delay -> returns distance matrix
crqa_part1 = crqa(part1$f0, part1$f0, embed = 2, delay = 1, normalize = 0, rescale = 0, radius = 0.5, mindiagline = 2, minvertline = 1)

#Making a graph of the rqa
RP = crqa_part1$RP
RP = matrix(as.numeric(RP), nrow = ncol(RP)) 
cols = c("white","blue4")
image(RP, xlab = "", ylab = "", col = cols)

```


2. Second you will have to turn the code into a function and loop through all the files (or even better use apply/sapply/lapply)
- Remember to extract the relevant information from the file names (Participant, Diagnosis, Trial, Study)

```{r}
folder = "C:/Users/Ejer/Desktop/3. semester/Experimental Methods 3/Assignment2/Pitch" 

filelist = list.files(path = folder , pattern = "*.txt", full.names = T)


opt_param_extractor = function(filename){ #A function which extract the optimal parameters (which is needed for running a rqa)
  temp_df = read.delim(filename) #reading the datafiles
  par = list(lgM =  15, steps = seq(1, 6, 1),  radiusspan = 100,  radiussample = 40, normalize = 0,  rescale = 0,  mindiagline = 2,  minvertline = 2,  tw = 0,  whiteline = FALSE,  recpt = FALSE,  fnnpercent = 10,  typeami = "mindip") #specifying the parameters for the rqa
  opt_param = NULL #making an empty optimal paramters list, in which they can be stored as they are computed
  opt_param = try(optimizeParam(temp_df$f0, temp_df$f0, par, min.rec = 3, max.rec = 4)) #calculating the optimal parameters using optimizePatam()
  #if else statement - if length of opt_param is bigger than 1 fill the results into the result dataframe. Else insert NA's
  if (length(opt_param) > 1) {
    result_df = data.frame(radius = opt_param[1], emddim = opt_param[2], delay = opt_param[3], filename = filename)
    
  } else {
  result_df = data.frame(radius = NA, emddim = NA, delay = NA, filename = filename)
  }
  return(result_df)
} 

temp=lapply(filelist,opt_param_extractor) #applying the opt_param_extractor function, making a temp object, where optimal paramters from files are stored
opt_param_df = rbindlist(temp, fill = T) #making a dataframe with the optimal paramters

#Creating a opt_df with the opt parameters best descriping the all the data (finding the median of the extracted parameter-values)
opt_df = data.frame(opt_rad = median(opt_param_df$radius, na.rm = T),
                    opt_emddim=median(opt_param_df$emddim, na.rm = T),
                    opt_delay = median(opt_param_df$delay, na.rm = T))


rqa_extractor = function(filename){ #making a function which applies the optimal parameters to perform an rqa, and save the results
  temp_df = read.delim(filename) #read data
  result = try(crqa(temp_df$f0, temp_df$f0, embed = opt_df$opt_emddim, delay = opt_df$opt_delay, radius = opt_df$opt_rad, normalize = 0, rescale = 0, mindiagline = 2, minvertline = 2)) #performing the crqa function -> use try so it continues to run even if crqa() fails
  #if else statement to return either results or NA's (if crqa() fails - same procedure as the first function)
  if (length(result) > 1) {
    result_df = data.frame(RR = result[1], DET = result[2], NRLINE = result[3],
             maxL = result[4], L = result[5], ENTR = result[6],
             rENTR = result[7], LAM = result[8], TT = result[9], 
             filename = filename)
     ##RR = percentage of black dots, DET = how many of the individual repitions occur in connected trajectories, L = average length of line structures, maxL = longest line, ENTR = entrophy (predictability of the next dot), TT = average length of vertical lines
  } else {
  result_df = data.frame(RR = NA, DET = NA, NRLINE = NA,
             maxL = NA, L = NA, ENTR = NA,
             rENTR = NA, LAM = NA, TT = NA, 
             filename = filename)
  } #extracting standard and less standard descriptors 
  result_df$meanv = mean(temp_df$f0, rm.na = T)
  result_df$sdv = sd(temp_df$f0)
  result_df$medianv = median(temp_df$f0)
  result_df$rangev = max(temp_df$f0) - min(temp_df$f0)
  result_df$iqrv = IQR(temp_df$f0)
  result_df$madv = mad(temp_df$f0)
  result_df$coefvarv = sd(temp_df$f0)/mean(temp_df$f0)
  return(result_df)
}

temp2 = lapply(filelist, rqa_extractor) #applying the rqa_extractor to the files, making an temp object with results
schizo_df = rbindlist(temp2, fill = T) #a dataframe with all the rqa parameters and other descriptors (acoustic features)

#Getting all the participant nformation stored in filename into seperate columns:

schizo_df$filename = str_extract(schizo_df$filename, "Study\\w+")
schizo_df$study = str_extract(schizo_df$filename, "\\d+")
schizo_df$diagnosis = str_extract(str_extract(schizo_df$filename, "D\\d+"), "\\d+")
schizo_df$ID = str_extract(str_extract(schizo_df$filename, "S\\d+"), "\\d+")
schizo_df$trial = str_extract(str_extract(schizo_df$filename, "T\\d+"), "\\d+")
schizo_df = subset(schizo_df, select = -c(filename))

#Note to self; For Diagnosis variable: 0 = control, 1 = schizophrenia, rename it?
```

3. Make one model per acoustic feature and test whether you can observe significant difference due to Diagnosis. Tip: Which other fixed factors should you control for (that is, include in the model)? Which random ones?
- Bonus points: cross-validate the model and report the betas and standard errors from all rounds to get an idea of how robust the estimates are. 
3a. Is study a significant predictor in these models? What should you infer from this? Does study interact with diagnosis? What should you infer from this?

```{r}
#Making a model pr. acoustic feature - acoustic features = range, mean, median, RR, DET, ENTR, LAM, TT, L, maxL) 

acousticFeatures = read.csv("AcousticFeatures.csv")
acousticFeatures = subset(acousticFeatures, select = -c(X))

acousticFeatures$diagnosis = as.factor(acousticFeatures$diagnosis)
acousticFeatures$NRLINE = as.numeric(acousticFeatures$NRLINE)
acousticFeatures$maxL = as.numeric(acousticFeatures$maxL)

m1 = lmerTest::lmer(rangev~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study), acousticFeatures)
summary(m1)

m2 = lmerTest::lmer(medianv~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study), acousticFeatures)
summary(m2)

m3 = lmerTest::lmer(DET~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study), acousticFeatures, REML = F)
summary(m3)

m4 = lmerTest::lmer(ENTR~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study), acousticFeatures, REML = F)
summary(m4)

m5 = lmerTest::lmer(LAM~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study), acousticFeatures)
summary(m5)

m6 = lmerTest::lmer(TT~1+trial+diagnosis +(1+trial+diagnosis|ID)+(1|study), acousticFeatures, REML = F)
summary(m6)

m7 = lmerTest::lmer(maxL~1+trial+diagnosis +(1+trial+diagnosis|ID)+(1|study), acousticFeatures, REML = F)
summary(m7)

m8 = lmerTest::lmer(RR~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study),acousticFeatures,REML = F)
summary(m8)

m9 = lmerTest::lmer(meanv~1+trial+diagnosis+(1+trial+diagnosis|ID)+(1|study),acousticFeatures,REML = F)
summary(m9)

#Which fixed factors and which random ones?
#Random intercept = ID (several data point pr. participant, particpants can have individual intercepts/starting points)
  #Random slope = trial (participants can vary over for each trial --> systematic variance between each trial)

#Study as significant predictor?
#What is study?, adding study as a random effect --> controlling for variability between the studies (might be systematc error --> the different studies are carried out by different researchers)

#Interaction between study and diagnossis?
m10 = lmerTest::lmer()

#recurrence rate is higher = crosses the same dimensions in the phase space more often --> they reccur 
```

4. Bonus Question: Compare effect size of diagnosis across the different measures. Which measure seems most sensitive?
- Tip: to compare across measures you need to put all of them on the same scale, that is, you need to "standardize" them (z-score)

5. Bonus question. In the Clinical Info file you have additional information about the participants. Which additional parameters (e.g. age, gender) should we control for? Report the effects.

6. Write a paragraph reporting methods and results

[Next assignment: can we use these measures to build a tool that diagnoses people from voice only?]

## N.B. Remember to save the acoustic features of voice in a separate file, so to be able to load them next time

```{r}
write.csv(schizo_df,"AcousticFeatures.csv")
```